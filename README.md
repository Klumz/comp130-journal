# comp130-journal
Base repository for COMP130 research journal

# Blue Eyes Technology

## Introduction
Humans depend on their ability to perceive, interpret, and react to information. However, could such sensory abilities be implemented and programmed for computers? This is where blue eyes technology comes into play. It is the technology built for analysing, detecting, and reacting accordingly to human emotions used with various electronic gadgets, such as a camera. This technology aims to enable computational machines to absorb and interact with humans based on their emotional information, allowing a natural interaction between the two. The **blue** in **blue eyes** stands for 'bluetooth', which is what enables wireless communication. **Eyes** simply refers to human eyes and their ability to move and gather information. Common Blue Eyes methods involve speech and facial recognition [1].

## The potential
Different types of experimental sensors have been created and proposed to capture emotional states, an example being the **Emotion Mouse** [2]. This device in particular gathers emotional information through touch, which it then reacts to by adapting to the user's emotions to create a better work environment, ultimately aiming to improve user productivity. Another one is the **eyePHONE**, an experimental device that allows users to initiate phone calls by holding eye contact to their eyePHONE, and assuming the receiver agrees to the initiation, they accept it by also looking at their eyePHONE, facilitating the use of basic social norms for initiating conversations [3]. Additionally, this device conveys non-verbal availability, as opposed to phone calls, subtly explaining if the caller is currently busy or not. Such systems and technologies can be implemented for, for instance, disabled individuals. While merely experiments, they can be further developed and improved in order to provide ease of accessibility not only for disabled individuals, but potentially for the business side of the industry as well, where user productivity is emphasised. 

## Conclusion
Blue Eyes technology involves creating systems and devices that work either in business (such as the Emotion Mouse) situations, or primarily to enable ease of access for impaired individuals of varying kinds (such as the eyePHONE). Further research and development are required for this specific field, however has major potential if both existing and new gadgets are programmed, improved and implemented respectfully. 

## Sources:

[Blue Eyes Technology](http://ieeexplore.ieee.org.ezproxy.falmouth.ac.uk/stamp/stamp.jsp?arnumber=6693995)

This paper introduces a new technique called "Emotion Sensory World", where human emotions are analysed and detected through machine eyes. This is done by a camera taking an image of said eye, processes it using a texture filtering algorithm, then is finally compared with the list of images stores in database. Examples of the emotional distinctions include: 

Happiness: Relaxed and neutral eyes

Anger: Eyebrows are pulled down and inward

Surprise: Eyebrows are raised and curved.


[The Emotion Mouse](https://pdfs.semanticscholar.org/91d8/2d479b4469cfc8b2c52005a3f8bbf7d28aae.pdf)

This paper proposes a method for gaining emotional user information through touch, the Emotion Mouse. It provides both a theory and experimentation. The four physiological readings measured during the experiment were heart rate, temperature, GSR (galvanic skin response, basically changes in the electrical resistance of the skin caused by stress, measurable with a galvanometer, e.g. in lie-detector tests.) and somatic movement. Ultimately, the results indicated the theory behind the Emotion Mouse work are fundamentally sound. The physiological measurements correlated to emotions using a correlation model.


[Establishing Remote Conversations Through Eye Contact With Physical Awareness Proxies](https://static1.squarespace.com/static/519d10a2e4b090350a2b66a0/t/51e5525be4b0ead5a3b6de6c/1373983323680/p948-jabarin.pdf)

This paper presents a mechanism for initiating remote conversations between two users through eye contact, the eyePHONE. It conveys attention using an eye tracking device and a pair of synthetic, proxy eyeballs. The calls are initiated by looking, for a set amount of time, at each other's eyePHONE.

"Face-to-face interactions provide a rich selection of verbal and non-verbal cues that allow potential interlocutors to negotiate the availability of their attention with great subtlety."


[An Active Model For Facial Feature Tracking](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.1837&rep=rep1&type=pdf)

This paper provides a system that tracks face and facial features in an MP4 video sequence, as well as an experiment showcasing its notable results. It works in real-time, and should be applicable on consumer hardware provided it receives further development.


[Hybrid Technique for Human Face Emotion Detection](http://ijsetr.com/uploads/435621IJSETR4235-180.pdf)

This paper presents an approach for emotion detection in heavily [noisy images](https://en.wikipedia.org/wiki/Image_noise), focusing on removal of noise from said images. The emotions used are anger, fear, happiness and neutral.


[Perceptual User Interfaces using Vision-based Eye Tracking](http://www.cc.gatech.edu/cpl/projects/multicameyetracking/papers/PrePrint.pdf)

This paper presents an experiment on a head pose tracking system with the use of multiple cameras in indoor settings under varying lighting conditions. 

"A significant amount of past research in human factors suggests that humans are generally interested in what they look at [20, 5]."

